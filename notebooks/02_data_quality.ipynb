{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba73dcef-2a92-4b39-a7d2-25e9f2f22534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/ruchita/data_engineering_projects/data_engineering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"Project root:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7162d5-2ad5-4f5a-b4e5-2eb39f1d6338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/05 01:37:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/05 01:37:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2026-02-05 01:37:47,916 - INFO - data-quality - Spark session started\n"
     ]
    }
   ],
   "source": [
    "from src.utils import create_spark_session, get_logger, write_df, get_path\n",
    "from src.validations import validate_transactions\n",
    "\n",
    "spark = create_spark_session(\n",
    "    os.path.join(project_root, \"configs\", \"spark_config.yaml\")\n",
    ")\n",
    "\n",
    "logger = get_logger(\"data-quality\")\n",
    "logger.info(\"Spark session started\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed736b7-53a3-4d44-aa8e-5d935e2918cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 01:38:10,377 - INFO - data-quality - Bronze records count: 20000     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+--------+----------------+--------+-------+---------------------+-------+\n",
      "|transaction_id|account_id|customer_id|  amount|transaction_type|merchant|country|transaction_timestamp| status|\n",
      "+--------------+----------+-----------+--------+----------------+--------+-------+---------------------+-------+\n",
      "|   TXN00000001| ACC001179|  CUST00316|20087.89|             ATM|  Amazon|    UAE|  2025-12-19 00:40:38|SUCCESS|\n",
      "|   TXN00000002| ACC001247|  CUST00910|35292.43|            CARD|    Noon|     SG|  2026-01-03 00:40:38| FAILED|\n",
      "|   TXN00000003| ACC000015|  CUST00654| 6304.01|             ATM|  Careem|     UK|  2025-04-11 00:40:38|SUCCESS|\n",
      "|   TXN00000004| ACC000879|  CUST00160|23516.83|          ONLINE|  Careem|     SG|  2025-06-04 00:40:38| FAILED|\n",
      "|   TXN00000005| ACC000078|  CUST00315| 8049.74|            CARD| Talabat|    UAE|  2025-04-02 00:40:38|SUCCESS|\n",
      "+--------------+----------+-----------+--------+----------------+--------+-------+---------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "bronze_path = get_path(\n",
    "    os.path.join(project_root, \"data\", \"processed\"),\n",
    "    \"bronze\",\n",
    "    \"transactions\"\n",
    ")\n",
    "\n",
    "bronze_df = spark.read.parquet(bronze_path)\n",
    "\n",
    "logger.info(f\"Bronze records count: {bronze_df.count()}\")\n",
    "bronze_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a6afd-9cde-40d7-bdb8-d393f46f130a",
   "metadata": {},
   "source": [
    "## Data Quality Rules Applied\n",
    "- Amount must be greater than 0\n",
    "- Transaction timestamp must not be NULL\n",
    "- Customer ID must not be NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb45e56-f03e-44f8-9738-7a7921f54b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 01:39:41,488 - INFO - data-quality - Valid records count: 20000\n",
      "2026-02-05 01:39:41,488 - INFO - data-quality - Invalid records count: 0\n"
     ]
    }
   ],
   "source": [
    "valid_df, invalid_df = validate_transactions(bronze_df)\n",
    "\n",
    "valid_count = valid_df.count()\n",
    "invalid_count = invalid_df.count()\n",
    "\n",
    "logger.info(f\"Valid records count: {valid_count}\")\n",
    "logger.info(f\"Invalid records count: {invalid_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ecb13e4-504f-497c-8bf8-6b33c1eaa3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+------+----------------+--------+-------+---------------------+------+\n",
      "|transaction_id|account_id|customer_id|amount|transaction_type|merchant|country|transaction_timestamp|status|\n",
      "+--------------+----------+-----------+------+----------------+--------+-------+---------------------+------+\n",
      "+--------------+----------+-----------+------+----------------+--------+-------+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invalid_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ac011b-f66e-4264-b14a-06a59c0fb54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 01:40:09,026 - INFO - data-quality - Silver clean transactions written\n"
     ]
    }
   ],
   "source": [
    "silver_clean_path = get_path(\n",
    "    os.path.join(project_root, \"data\", \"processed\"),\n",
    "    \"silver\",\n",
    "    \"transactions_clean\"\n",
    ")\n",
    "\n",
    "write_df(\n",
    "    valid_df,\n",
    "    silver_clean_path,\n",
    "    mode=\"overwrite\"\n",
    ")\n",
    "\n",
    "logger.info(\"Silver clean transactions written\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9891696-1a73-4855-85b9-82e727f89a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 01:40:37,442 - INFO - data-quality - Silver invalid transactions written\n"
     ]
    }
   ],
   "source": [
    "silver_invalid_path = get_path(\n",
    "    os.path.join(project_root, \"data\", \"processed\"),\n",
    "    \"silver\",\n",
    "    \"transactions_invalid\"\n",
    ")\n",
    "\n",
    "write_df(\n",
    "    invalid_df,\n",
    "    silver_invalid_path,\n",
    "    mode=\"overwrite\"\n",
    ")\n",
    "\n",
    "logger.info(\"Silver invalid transactions written\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a800d266-4913-4237-b875-2733e48cb270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean records: 20000\n",
      "Invalid records: 0\n"
     ]
    }
   ],
   "source": [
    "clean_df = spark.read.parquet(silver_clean_path)\n",
    "invalid_df_check = spark.read.parquet(silver_invalid_path)\n",
    "\n",
    "print(\"Clean records:\", clean_df.count())\n",
    "print(\"Invalid records:\", invalid_df_check.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30891acf-8a17-496c-9d4d-fdb7de223c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528cf19f-b443-47dc-b859-786d6087f9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/ruchita/data_engineering_projects/data_engineering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"Project root:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db35b6d7-6f75-458b-914f-8b8eff62e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/05 02:38:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/05 02:38:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/02/05 02:38:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "26/02/05 02:38:10 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "26/02/05 02:38:10 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "2026-02-05 02:38:10,355 - INFO - performance-optimizations - Spark session started\n"
     ]
    }
   ],
   "source": [
    "from src.utils import create_spark_session, get_logger, get_path\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "spark = create_spark_session(\n",
    "    os.path.join(project_root, \"configs\", \"spark_config.yaml\")\n",
    ")\n",
    "\n",
    "logger = get_logger(\"performance-optimizations\")\n",
    "logger.info(\"Spark session started\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb85d24-a611-4e07-97ef-60ebf862696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 02:38:21,789 - INFO - performance-optimizations - Total records: 20000\n",
      "[Stage 4:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+--------+----------------+--------+-------------------+---------------------+-------+--------------------+----------+----------------+---------+------------+---------+------------+----------+-----------------+\n",
      "|account_id|customer_id|transaction_id|  amount|transaction_type|merchant|transaction_country|transaction_timestamp| status|       customer_name|       dob|customer_country|  segment|account_type|  balance|created_date|  txn_date|is_high_value_txn|\n",
      "+----------+-----------+--------------+--------+----------------+--------+-------------------+---------------------+-------+--------------------+----------+----------------+---------+------------+---------+------------+----------+-----------------+\n",
      "| ACC001179|  CUST00316|   TXN00000001|20087.89|             ATM|  Amazon|                UAE|  2025-12-19 00:40:38|SUCCESS|          Craig Dunn|1996-05-07|              US|Corporate|     Savings|174771.68|  2024-09-03|2025-12-19|                1|\n",
      "| ACC001247|  CUST00910|   TXN00000002|35292.43|            CARD|    Noon|                 SG|  2026-01-03 00:40:38| FAILED|   Robert Harrington|1985-11-12|             UAE|Corporate|     Savings|186251.92|  2018-05-11|2026-01-03|                1|\n",
      "| ACC000015|  CUST00654|   TXN00000003| 6304.01|             ATM|  Careem|                 UK|  2025-04-11 00:40:38|SUCCESS|         Mary Deleon|1981-08-09|              UK|   Retail|      Credit| 23278.63|  2018-10-30|2025-04-11|                0|\n",
      "| ACC000879|  CUST00160|   TXN00000004|23516.83|          ONLINE|  Careem|                 SG|  2025-06-04 00:40:38| FAILED|Beverly Franklin DDS|1959-07-24|              US|   Retail|     Current|109158.78|  2024-02-24|2025-06-04|                1|\n",
      "| ACC000078|  CUST00315|   TXN00000005| 8049.74|            CARD| Talabat|                UAE|  2025-04-02 00:40:38|SUCCESS|     Elizabeth Myers|1962-12-22|              UK|   Retail|     Current|161955.46|  2017-04-08|2025-04-02|                0|\n",
      "+----------+-----------+--------------+--------+----------------+--------+-------------------+---------------------+-------+--------------------+----------+----------------+---------+------------+---------+------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "silver_enriched_path = get_path(\n",
    "    os.path.join(project_root, \"data\", \"processed\"),\n",
    "    \"silver\",\n",
    "    \"transactions_enriched\"\n",
    ")\n",
    "\n",
    "df = spark.read.parquet(silver_enriched_path)\n",
    "\n",
    "logger.info(f\"Total records: {df.count()}\")\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77a976b-7976-4eba-b3e2-8acdbd93b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution plan BEFORE optimizations:\n",
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['customer_id], ['customer_id, count(1) AS count#152L]\n",
      "+- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "customer_id: string, count: bigint\n",
      "Aggregate [customer_id#1], [customer_id#1, count(1) AS count#152L]\n",
      "+- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [customer_id#1], [customer_id#1, count(1) AS count#152L]\n",
      "+- Project [customer_id#1]\n",
      "   +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[customer_id#1], functions=[count(1)], output=[customer_id#1, count#152L])\n",
      "   +- Exchange hashpartitioning(customer_id#1, 200), ENSURE_REQUIREMENTS, [plan_id=62]\n",
      "      +- HashAggregate(keys=[customer_id#1], functions=[partial_count(1)], output=[customer_id#1, count#156L])\n",
      "         +- FileScan parquet [customer_id#1] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<customer_id:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution plan BEFORE optimizations:\")\n",
    "df.groupBy(\"customer_id\").count().explain(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9035b2b7-5a53-47cf-a151-4a3833c15754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial partitions: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial partitions:\", df.rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f0fd29-c1e6-4dcd-ae14-a693657bf72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions after repartition: 2\n"
     ]
    }
   ],
   "source": [
    "df_repartitioned = df.repartition(\"txn_date\")\n",
    "\n",
    "print(\"Partitions after repartition:\", df_repartitioned.rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51f220c-207e-47eb-b565-b022059cad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repartitioned.cache()\n",
    "df_repartitioned.count()  # materialize cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b1ae04-0c33-4510-a47e-ecce35837085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution plan AFTER optimizations:\n",
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['customer_id], ['customer_id, count(1) AS count#739L]\n",
      "+- RepartitionByExpression [txn_date#16]\n",
      "   +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "customer_id: string, count: bigint\n",
      "Aggregate [customer_id#1], [customer_id#1, count(1) AS count#739L]\n",
      "+- RepartitionByExpression [txn_date#16]\n",
      "   +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [customer_id#1], [customer_id#1, count(1) AS count#739L]\n",
      "+- Project [customer_id#1]\n",
      "   +- InMemoryRelation [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- Exchange hashpartitioning(txn_date#16, 200), REPARTITION_BY_COL, [plan_id=156]\n",
      "            +- *(1) ColumnarToRow\n",
      "               +- FileScan parquet [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<account_id:string,customer_id:string,transaction_id:string,amount:double,transaction_type:...\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[customer_id#1], functions=[count(1)], output=[customer_id#1, count#739L])\n",
      "   +- Exchange hashpartitioning(customer_id#1, 200), ENSURE_REQUIREMENTS, [plan_id=168]\n",
      "      +- HashAggregate(keys=[customer_id#1], functions=[partial_count(1)], output=[customer_id#1, count#1013L])\n",
      "         +- InMemoryTableScan [customer_id#1]\n",
      "               +- InMemoryRelation [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- Exchange hashpartitioning(txn_date#16, 200), REPARTITION_BY_COL, [plan_id=174]\n",
      "                        +- *(1) ColumnarToRow\n",
      "                           +- FileScan parquet [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<account_id:string,customer_id:string,transaction_id:string,amount:double,transaction_type:...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution plan AFTER optimizations:\")\n",
    "df_repartitioned.groupBy(\"customer_id\").count().explain(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9231a5-170f-4e60-a469-c2723a8479ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(LeftOuter, [customer_id])\n",
      ":- RepartitionByExpression [txn_date#16]\n",
      ":  +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- Relation [customer_id#1031,customer_name#1032,dob#1033,country#1034,segment#1035] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "customer_id: string, account_id: string, transaction_id: string, amount: double, transaction_type: string, merchant: string, transaction_country: string, transaction_timestamp: timestamp, status: string, customer_name: string, dob: date, customer_country: string, segment: string, account_type: string, balance: double, created_date: date, txn_date: date, is_high_value_txn: int, customer_name: string, dob: date, country: string, segment: string\n",
      "Project [customer_id#1, account_id#0, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17, customer_name#1032, dob#1033, country#1034, segment#1035]\n",
      "+- Join LeftOuter, (customer_id#1 = customer_id#1031)\n",
      "   :- RepartitionByExpression [txn_date#16]\n",
      "   :  +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "   +- ResolvedHint (strategy=broadcast)\n",
      "      +- Relation [customer_id#1031,customer_name#1032,dob#1033,country#1034,segment#1035] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [customer_id#1, account_id#0, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17, customer_name#1032, dob#1033, country#1034, segment#1035]\n",
      "+- Join LeftOuter, (customer_id#1 = customer_id#1031), rightHint=(strategy=broadcast)\n",
      "   :- InMemoryRelation [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     +- Exchange hashpartitioning(txn_date#16, 200), REPARTITION_BY_COL, [plan_id=198]\n",
      "   :        +- *(1) ColumnarToRow\n",
      "   :           +- FileScan parquet [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<account_id:string,customer_id:string,transaction_id:string,amount:double,transaction_type:...\n",
      "   +- Filter isnotnull(customer_id#1031)\n",
      "      +- Relation [customer_id#1031,customer_name#1032,dob#1033,country#1034,segment#1035] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [customer_id#1, account_id#0, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17, customer_name#1032, dob#1033, country#1034, segment#1035]\n",
      "   +- BroadcastHashJoin [customer_id#1], [customer_id#1031], LeftOuter, BuildRight, false\n",
      "      :- InMemoryTableScan [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17]\n",
      "      :     +- InMemoryRelation [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :           +- Exchange hashpartitioning(txn_date#16, 200), REPARTITION_BY_COL, [plan_id=228]\n",
      "      :              +- *(1) ColumnarToRow\n",
      "      :                 +- FileScan parquet [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<account_id:string,customer_id:string,transaction_id:string,amount:double,transaction_type:...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=221]\n",
      "         +- Filter isnotnull(customer_id#1031)\n",
      "            +- FileScan csv [customer_id#1031,customer_name#1032,dob#1033,country#1034,segment#1035] Batched: false, DataFilters: [isnotnull(customer_id#1031)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/ra..., PartitionFilters: [], PushedFilters: [IsNotNull(customer_id)], ReadSchema: struct<customer_id:string,customer_name:string,dob:date,country:string,segment:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_path = os.path.join(project_root, \"data\", \"raw\", \"customers.csv\")\n",
    "customers_df = spark.read.csv(customers_path, header=True, inferSchema=True)\n",
    "\n",
    "optimized_join_df = df_repartitioned.join(\n",
    "    customers_df.hint(\"broadcast\"),\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "optimized_join_df.explain(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97871e5-d515-4099-aa68-964fa96f1474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['txn_date], ['txn_date, sum(amount#3) AS sum(amount)#1353]\n",
      "+- RepartitionByExpression [txn_date#16]\n",
      "   +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "txn_date: date, sum(amount): double\n",
      "Aggregate [txn_date#16], [txn_date#16, sum(amount#3) AS sum(amount)#1353]\n",
      "+- RepartitionByExpression [txn_date#16]\n",
      "   +- Relation [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [txn_date#16], [txn_date#16, sum(amount#3) AS sum(amount)#1353]\n",
      "+- Project [amount#3, txn_date#16]\n",
      "   +- InMemoryRelation [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- Exchange hashpartitioning(txn_date#16, 200), REPARTITION_BY_COL, [plan_id=233]\n",
      "            +- *(1) ColumnarToRow\n",
      "               +- FileScan parquet [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<account_id:string,customer_id:string,transaction_id:string,amount:double,transaction_type:...\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[txn_date#16], functions=[sum(amount#3)], output=[txn_date#16, sum(amount)#1353])\n",
      "   +- HashAggregate(keys=[txn_date#16], functions=[partial_sum(amount#3)], output=[txn_date#16, sum#1627])\n",
      "      +- InMemoryTableScan [amount#3, txn_date#16]\n",
      "            +- InMemoryRelation [account_id#0, customer_id#1, transaction_id#2, amount#3, transaction_type#4, merchant#5, transaction_country#6, transaction_timestamp#7, status#8, customer_name#9, dob#10, customer_country#11, segment#12, account_type#13, balance#14, created_date#15, txn_date#16, is_high_value_txn#17], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                  +- Exchange hashpartitioning(txn_date#16, 200), REPARTITION_BY_COL, [plan_id=249]\n",
      "                     +- *(1) ColumnarToRow\n",
      "                        +- FileScan parquet [account_id#0,customer_id#1,transaction_id#2,amount#3,transaction_type#4,merchant#5,transaction_country#6,transaction_timestamp#7,status#8,customer_name#9,dob#10,customer_country#11,segment#12,account_type#13,balance#14,created_date#15,txn_date#16,is_high_value_txn#17] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/ruchita/data_engineering_projects/data_engineering/data/pr..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<account_id:string,customer_id:string,transaction_id:string,amount:double,transaction_type:...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "\n",
    "df_repartitioned.groupBy(\"txn_date\").sum(\"amount\").explain(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98b4df-2574-4cf6-9b98-ad611dd33fff",
   "metadata": {},
   "source": [
    "## Small Files Problem\n",
    "- Caused by excessive partitioning\n",
    "- Solved using repartition/coalesce\n",
    "- Impacts query latency and metadata load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b283b7b6-f775-4af8-ba74-ebb0581d5689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions after coalesce: 10\n"
     ]
    }
   ],
   "source": [
    "df_coalesced = df_repartitioned.coalesce(10)\n",
    "print(\"Partitions after coalesce:\", df_coalesced.rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a028ebf-caaa-4b98-89d2-5a6c82e745d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 02:41:45,466 - INFO - performance-optimizations - Cache cleared\n"
     ]
    }
   ],
   "source": [
    "df_repartitioned.unpersist()\n",
    "logger.info(\"Cache cleared\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40569a61-e319-4a44-827a-409310d1da97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
